{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/koerner/Desktop/robert-power-and-language-files-osf/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s] %(name)s: %(message)s\")\n",
    "\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] data: Clean study data ...\n"
     ]
    }
   ],
   "source": [
    "fn_study_prepared = \"studydata.pickle\"\n",
    "\n",
    "if not os.path.exists(fn_study_prepared):\n",
    "    df_study1, df_study2 = data.prepare_study_data()\n",
    "\n",
    "    with open(fn_study_prepared, \"wb\") as fp:\n",
    "        pickle.dump(df_study1, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(df_study2, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(fn_study_prepared, \"rb\") as fp:\n",
    "    df_study1 = pickle.load(fp)\n",
    "    df_study2 = pickle.load(fp)\n",
    "\n",
    "df_study1, df_study2 = data.clean_study_data(df_study1, df_study2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study1[[\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\"]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study2[[\"power\", \"dominance\", \"prestige\", \"workplace_power\", \"power_f\", \"dominance_f\", \"prestige_f\", \"workplace_power_f\"]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = \"power\"\n",
    "\n",
    "print(what, end=\":\\n\")\n",
    "print(\"  min=\", df_study1[what].min())\n",
    "print(\"  max=\", df_study1[what].max())\n",
    "# quantiles (low / mid / hig)\n",
    "df_study1[[\"power\", \"dominance\", \"prestige\"]].quantile([0, 1/3, 2/3, 3/3])\n",
    "\n",
    "# normal hist\n",
    "#df_study1[\"power\"].hist()\n",
    "# by quantiles\n",
    "#(df_study1[\"power\"] / df_study1[\"power\"].abs().max()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = \"power\"\n",
    "\n",
    "# by quantiles\n",
    "df_study1[what].hist()\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "q33 = df_study1[what].quantile(1/3)\n",
    "q66 = df_study1[what].quantile(2/3)\n",
    "plt.axvline(q33, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.text(q33*1.01, max_ylim*0.9, '{:.2f}'.format(q33))\n",
    "plt.axvline(q66, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.text(q66*1.01, max_ylim*0.9, '{:.2f}'.format(q66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "# _ = data.get_lmh_quantiles_mask(df_study1, \"power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study1_quants = df_study1[[\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\"]].quantile([1/3, 2/3])\n",
    "df_study1_quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study2_quants = df_study2[[\"power\", \"dominance\", \"prestige\", \"workplace_power\", \"power_f\", \"dominance_f\", \"prestige_f\", \"workplace_power_f\"]].quantile([1/3, 2/3])\n",
    "df_study2_quants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (\"NOUN\", \"PROPN\")\n",
    "#pos = (\"ADJ\",)\n",
    "#pos = (\"ADV\",)\n",
    "#pos = (\"VERB\",)\n",
    "# https://universaldependencies.org/u/pos/\n",
    "lemma = True\n",
    "relative = False\n",
    "total_occ_min = 10  # at least 10 occurences (summed)\n",
    "#total_occ_min = 5   # if ADJ then less words required\n",
    "\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    df_lmh = data.make_word_freq_score_lmh_comparison_df(df_study1, what, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "    df_lmh.plot(kind=\"barh\")\n",
    "    plt.title(\"Words for '{}' for {}\".format(what.title(), \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = (0., 1/3)\n",
    "range_ = (1/3, 2/3)\n",
    "#range_ = (2/3, 1.)\n",
    "\n",
    "whats = (\"power\", \"dominance\", \"prestige\")\n",
    "whats = (\"power_f\", \"dominance_f\", \"prestige_f\")\n",
    "#whats = (\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\")\n",
    "relative = True\n",
    "\n",
    "df_h_pdp = data.make_word_freq_score_pdp_comparison_df(df_study1, whats=whats, range_=range_, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "df_h_pdp.plot(kind=\"barh\")\n",
    "plt.title(\"Words for quantile {:.2f}-{:.2f} for {}\".format(*range_, \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = (2/3, 1.)\n",
    "relative = True\n",
    "whatss = [(\"power\", \"power_f\"), (\"dominance\", \"dominance_f\"), (\"prestige\", \"prestige_f\")]\n",
    "\n",
    "pos = (\"NOUN\", \"PROPN\")\n",
    "#pos = (\"ADJ\",)\n",
    "#pos = (\"ADV\",)\n",
    "pos = (\"VERB\",)\n",
    "total_occ_min = 10  # at least 10 occurences (summed)\n",
    "#total_occ_min = 5   # if ADJ then less words required\n",
    "\n",
    "for whats in whatss:\n",
    "    df_h_pdp = data.make_word_freq_score_pdp_comparison_df(df_study1, whats=whats, range_=range_, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "    df_h_pdp.plot(kind=\"barh\")\n",
    "    plt.title(\"Words for quantile {:.2f}-{:.2f} for {}\".format(*range_, \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write_freqs_to_excel(df_study1, \"study1-output.xlsx\")\n",
    "data.write_freqs_to_excel(df_study2, \"study2-output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.generate_freqs_figures(df_study1, \"figures_study1\")\n",
    "data.generate_freqs_figures(df_study2, \"figures_study2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(data)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat = data.train_prepare(df_study1)\n",
    "\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    clf = data.train_model(df_study1, what, doc_term_mat=doc_term_mat)\n",
    "    coefs = clf.coef_.copy()\n",
    "\n",
    "    #coefs = data.normalize_coefs(coefs)\n",
    "\n",
    "    coefs = coefs * np.linspace(-1, 1, len(clf.classes_))[:,np.newaxis]\n",
    "    coefs = coefs.sum(axis=0)\n",
    "\n",
    "    coefs = data.normalize_coefs(coefs)\n",
    "\n",
    "    values, labels = data.coef_filter(coefs, clf.feature_names_in_)\n",
    "    desc = data.coef_to_human(values, labels)\n",
    "    print(what)\n",
    "    print(desc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat = data.train_prepare(df_study1)\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    clf = data.train_model(df_study1, what, doc_term_mat=doc_term_mat)\n",
    "    data.write_coefs_to_excel(clf, what, fn_output=\"study1-coefs.xlsx\", require_both=True)\n",
    "\n",
    "doc_term_mat = data.train_prepare(df_study2)\n",
    "for what in (\"power\", \"dominance\", \"prestige\", \"workplace_power\"):\n",
    "    clf = data.train_model(df_study2, what, doc_term_mat=doc_term_mat)\n",
    "    data.write_coefs_to_excel(clf, what, fn_output=\"study2-coefs.xlsx\", require_both=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = df_study1[\"text_spacy_doc_filtered\"]\n",
    "#doc_term_mat, features = data.build_count_matrix(df_sub)\n",
    "doc_term_mat, features = data.build_feature_matrix(df_sub, norm=\"l2\", use_idf=True)\n",
    "# doc_term_mat.toarray()\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "\n",
    "#clf = sklearn.linear_model.Lasso(alpha=0.1)\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "X = doc_term_mat\n",
    "y = df_study1[\"power\"].to_numpy()\n",
    "#y = y.astype(int)\n",
    "y = np.vectorize(round)(y)\n",
    "# to interval [0, 1]\n",
    "#y = (y - np.min(y)) / np.ptp(y)\n",
    "#y = y[:,np.newaxis]\n",
    "#plt.hist(y)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n",
    "\n",
    "#np.sort(clf.coef_[np.where(clf.coef_ > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "C = clf.coef_\n",
    "print(\"\\ncoefficients:\")\n",
    "print(C)\n",
    "# C / C.sum(axis=0)\n",
    "\n",
    "# norm: [0, 1]\n",
    "#C = (C - np.min(C)) / np.ptp(C)\n",
    "# norm: [-1, 1]\n",
    "C = 2. * (C - np.min(C)) / np.ptp(C) - 1\n",
    "#C = C / 2.\n",
    "\n",
    "# print words\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    srt = np.argsort(np.abs(Cc))[::-1]\n",
    "    mask = np.abs(Cc) > 0.25\n",
    "    mask_srt = mask[srt]\n",
    "    mask_srt[10:] = False\n",
    "    labels_srt = np.array(features)[srt][mask_srt]\n",
    "    values_srt = np.array(Cc)[srt][mask_srt]\n",
    "    srt = np.argsort(values_srt)[::-1]\n",
    "    labels_srt = labels_srt[srt]\n",
    "    values_srt = values_srt[srt]\n",
    "    desc = \" + \".join(\"{:.2f}*'{}'\".format(val, lbl) for lbl, val in zip(labels_srt, values_srt))\n",
    "    #desc = \" + \".join(\"{:.2f}*'{}'\".format(val, labels[i]) for i, val in enumerate(Cc))\n",
    "    print(\"Class\", class_, \"=\", desc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Class 3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Class 4</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Class 5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Class 6</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Class 7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coefs</th>\n",
       "      <th>words</th>\n",
       "      <th>coefs</th>\n",
       "      <th>words</th>\n",
       "      <th>coefs</th>\n",
       "      <th>words</th>\n",
       "      <th>coefs</th>\n",
       "      <th>words</th>\n",
       "      <th>coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empathisch</td>\n",
       "      <td>0.803768</td>\n",
       "      <td>kg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>eher</td>\n",
       "      <td>0.630842</td>\n",
       "      <td>Menschen</td>\n",
       "      <td>0.943616</td>\n",
       "      <td>selbstbewusst</td>\n",
       "      <td>0.727885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nachdenklich</td>\n",
       "      <td>0.675783</td>\n",
       "      <td>zurecht</td>\n",
       "      <td>0.657515</td>\n",
       "      <td>Kinder</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>Freunde</td>\n",
       "      <td>0.922560</td>\n",
       "      <td>kommunikativ</td>\n",
       "      <td>0.495415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schwere</td>\n",
       "      <td>0.551223</td>\n",
       "      <td>wiege</td>\n",
       "      <td>0.651797</td>\n",
       "      <td>Manchmal</td>\n",
       "      <td>0.617667</td>\n",
       "      <td>Mensch</td>\n",
       "      <td>0.840910</td>\n",
       "      <td>lesen</td>\n",
       "      <td>0.493894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>freundlich</td>\n",
       "      <td>0.439724</td>\n",
       "      <td>kennenzulernen</td>\n",
       "      <td>0.649295</td>\n",
       "      <td>Empathie</td>\n",
       "      <td>-0.611244</td>\n",
       "      <td>aufgeschlossen</td>\n",
       "      <td>0.709363</td>\n",
       "      <td>Neues</td>\n",
       "      <td>0.459237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talentiert</td>\n",
       "      <td>0.404398</td>\n",
       "      <td>Partnerschaft</td>\n",
       "      <td>0.555572</td>\n",
       "      <td>aufgeschlossen</td>\n",
       "      <td>-0.625688</td>\n",
       "      <td>hilfsbereit</td>\n",
       "      <td>0.672065</td>\n",
       "      <td>Drücker</td>\n",
       "      <td>0.415498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hilfsbereit</td>\n",
       "      <td>0.404398</td>\n",
       "      <td>introvertiert</td>\n",
       "      <td>0.517160</td>\n",
       "      <td>komme</td>\n",
       "      <td>-0.632858</td>\n",
       "      <td>umgehen</td>\n",
       "      <td>0.557359</td>\n",
       "      <td>bearbeiten</td>\n",
       "      <td>0.415498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verbindlich</td>\n",
       "      <td>0.404398</td>\n",
       "      <td>Teilzeit</td>\n",
       "      <td>0.501018</td>\n",
       "      <td>aufbrausend</td>\n",
       "      <td>-0.640129</td>\n",
       "      <td>manchmal</td>\n",
       "      <td>0.534792</td>\n",
       "      <td>Handwerklich</td>\n",
       "      <td>0.415498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ausbaufähig</td>\n",
       "      <td>0.404398</td>\n",
       "      <td>unterwegs</td>\n",
       "      <td>0.493105</td>\n",
       "      <td>kommunikativ</td>\n",
       "      <td>-0.648217</td>\n",
       "      <td>zielstrebig</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>gebe</td>\n",
       "      <td>0.409377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anpassungsfähig</td>\n",
       "      <td>0.404398</td>\n",
       "      <td>arbeite</td>\n",
       "      <td>0.468205</td>\n",
       "      <td>kg</td>\n",
       "      <td>-0.648412</td>\n",
       "      <td>Mann</td>\n",
       "      <td>-0.531523</td>\n",
       "      <td>letzten</td>\n",
       "      <td>0.363334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Romantiker</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>inzwischen</td>\n",
       "      <td>0.466566</td>\n",
       "      <td>beruflich</td>\n",
       "      <td>-0.658755</td>\n",
       "      <td>arbeite</td>\n",
       "      <td>-0.549577</td>\n",
       "      <td>begabt</td>\n",
       "      <td>0.352777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kurzer</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>kümmere</td>\n",
       "      <td>0.463708</td>\n",
       "      <td>nehme</td>\n",
       "      <td>-0.662117</td>\n",
       "      <td>neige</td>\n",
       "      <td>-0.559876</td>\n",
       "      <td>empatischer</td>\n",
       "      <td>0.347191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hose</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>positiv</td>\n",
       "      <td>-0.465702</td>\n",
       "      <td>Dinge</td>\n",
       "      <td>-0.676700</td>\n",
       "      <td>Hobbys</td>\n",
       "      <td>-0.582123</td>\n",
       "      <td>Kompromisse</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>alleine</td>\n",
       "      <td>-0.479587</td>\n",
       "      <td>zielstrebig</td>\n",
       "      <td>-0.678952</td>\n",
       "      <td>Leuten</td>\n",
       "      <td>-0.587581</td>\n",
       "      <td>durchsetzungsstark</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>meisten</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>liebe</td>\n",
       "      <td>-0.483186</td>\n",
       "      <td>Mutter</td>\n",
       "      <td>-0.702547</td>\n",
       "      <td>introvertiert</td>\n",
       "      <td>-0.630990</td>\n",
       "      <td>sinnvoll</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Emotional</td>\n",
       "      <td>0.393644</td>\n",
       "      <td>hilfsbereit</td>\n",
       "      <td>-0.498859</td>\n",
       "      <td>Freunde</td>\n",
       "      <td>-0.704711</td>\n",
       "      <td>relativ</td>\n",
       "      <td>-0.647801</td>\n",
       "      <td>sofern</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>verheiratet</td>\n",
       "      <td>0.383915</td>\n",
       "      <td>Arbeit</td>\n",
       "      <td>-0.510951</td>\n",
       "      <td>Menschen</td>\n",
       "      <td>-0.714695</td>\n",
       "      <td>Manchmal</td>\n",
       "      <td>-0.654492</td>\n",
       "      <td>eingehe</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eingestellt</td>\n",
       "      <td>0.358880</td>\n",
       "      <td>freundlich</td>\n",
       "      <td>-0.518312</td>\n",
       "      <td>harmoniebedürftig</td>\n",
       "      <td>-0.720096</td>\n",
       "      <td>kreativ</td>\n",
       "      <td>-0.667179</td>\n",
       "      <td>erscheint</td>\n",
       "      <td>0.338888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lebensfroh</td>\n",
       "      <td>0.358021</td>\n",
       "      <td>Freunde</td>\n",
       "      <td>-0.532211</td>\n",
       "      <td>lache</td>\n",
       "      <td>-0.795574</td>\n",
       "      <td>alt</td>\n",
       "      <td>-0.726467</td>\n",
       "      <td>Arbeit</td>\n",
       "      <td>0.324243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>grübele</td>\n",
       "      <td>0.358021</td>\n",
       "      <td>manchmal</td>\n",
       "      <td>-0.541908</td>\n",
       "      <td>hilfsbereit</td>\n",
       "      <td>-0.969330</td>\n",
       "      <td>mal</td>\n",
       "      <td>-0.796597</td>\n",
       "      <td>gerne</td>\n",
       "      <td>-0.413357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>emotionaler</td>\n",
       "      <td>0.358021</td>\n",
       "      <td>Mensch</td>\n",
       "      <td>-0.934554</td>\n",
       "      <td>empathisch</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>eher</td>\n",
       "      <td>-0.939130</td>\n",
       "      <td>Menschen</td>\n",
       "      <td>-0.422237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class 3                   Class 4                      Class 5  \\\n",
       "              words     coefs           words     coefs              words   \n",
       "0        empathisch  0.803768              kg  1.000000               eher   \n",
       "1      nachdenklich  0.675783         zurecht  0.657515             Kinder   \n",
       "2           schwere  0.551223           wiege  0.651797           Manchmal   \n",
       "3        freundlich  0.439724  kennenzulernen  0.649295           Empathie   \n",
       "4        talentiert  0.404398   Partnerschaft  0.555572     aufgeschlossen   \n",
       "5       Hilfsbereit  0.404398   introvertiert  0.517160              komme   \n",
       "6       verbindlich  0.404398        Teilzeit  0.501018        aufbrausend   \n",
       "7       ausbaufähig  0.404398       unterwegs  0.493105       kommunikativ   \n",
       "8   Anpassungsfähig  0.404398         arbeite  0.468205                 kg   \n",
       "9        Romantiker  0.393644      inzwischen  0.466566          beruflich   \n",
       "10           kurzer  0.393644         kümmere  0.463708              nehme   \n",
       "11             Hose  0.393644         positiv -0.465702              Dinge   \n",
       "12       Hufflepuff  0.393644         alleine -0.479587        zielstrebig   \n",
       "13          meisten  0.393644           liebe -0.483186             Mutter   \n",
       "14        Emotional  0.393644     hilfsbereit -0.498859            Freunde   \n",
       "15      verheiratet  0.383915          Arbeit -0.510951           Menschen   \n",
       "16      eingestellt  0.358880      freundlich -0.518312  harmoniebedürftig   \n",
       "17       lebensfroh  0.358021         Freunde -0.532211              lache   \n",
       "18          grübele  0.358021        manchmal -0.541908        hilfsbereit   \n",
       "19      emotionaler  0.358021          Mensch -0.934554         empathisch   \n",
       "\n",
       "                     Class 6                       Class 7            \n",
       "       coefs           words     coefs               words     coefs  \n",
       "0   0.630842        Menschen  0.943616       selbstbewusst  0.727885  \n",
       "1   0.619512         Freunde  0.922560        kommunikativ  0.495415  \n",
       "2   0.617667          Mensch  0.840910               lesen  0.493894  \n",
       "3  -0.611244  aufgeschlossen  0.709363               Neues  0.459237  \n",
       "4  -0.625688     hilfsbereit  0.672065             Drücker  0.415498  \n",
       "5  -0.632858         umgehen  0.557359          bearbeiten  0.415498  \n",
       "6  -0.640129        manchmal  0.534792        Handwerklich  0.415498  \n",
       "7  -0.648217     zielstrebig  0.515501                gebe  0.409377  \n",
       "8  -0.648412            Mann -0.531523             letzten  0.363334  \n",
       "9  -0.658755         arbeite -0.549577              begabt  0.352777  \n",
       "10 -0.662117           neige -0.559876         empatischer  0.347191  \n",
       "11 -0.676700          Hobbys -0.582123         Kompromisse  0.338888  \n",
       "12 -0.678952          Leuten -0.587581  durchsetzungsstark  0.338888  \n",
       "13 -0.702547   introvertiert -0.630990            sinnvoll  0.338888  \n",
       "14 -0.704711         relativ -0.647801              sofern  0.338888  \n",
       "15 -0.714695        Manchmal -0.654492             eingehe  0.338888  \n",
       "16 -0.720096         kreativ -0.667179           erscheint  0.338888  \n",
       "17 -0.795574             alt -0.726467              Arbeit  0.324243  \n",
       "18 -0.969330             mal -0.796597               gerne -0.413357  \n",
       "19 -1.000000            eher -0.939130            Menschen -0.422237  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = clf.coef_\n",
    "C = data.normalize_coefs(C)\n",
    "\n",
    "dfs_coefs = []\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = data.coef_filter(Cc, features, require_both=False)\n",
    "    col_lbl = \"Class {:d}\".format(int(class_))\n",
    "    cols = pd.MultiIndex.from_tuples([(col_lbl, \"words\"), (col_lbl, \"coefs\")])\n",
    "    df_coef = pd.DataFrame.from_records(data=zip(labels, values), columns=cols)\n",
    "    dfs_coefs.append(df_coef)\n",
    "\n",
    "df_coefs = pd.concat(dfs_coefs, axis=1)\n",
    "#df_coefs.columns = pd.MultiIndex.from_tuples(itertools.chain.from_iterable(((\"Class {:d}\".format(int(class_)), \"words\"), (\"Class {:d}\".format(int(class_)), \"coefs\")) for class_ in clf.classes_))\n",
    "df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "C = clf.coef_\n",
    "#print(\"\\ncoefficients:\")\n",
    "#print(C)\n",
    "# C / C.sum(axis=0)\n",
    "\n",
    "C = data.normalize_coefs(C)\n",
    "\n",
    "# print words\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = data.coef_filter(Cc, features, require_both=False)\n",
    "    desc = data.coef_to_human(values, labels)\n",
    "    print(\"Class {}: {}\\n\".format(class_, desc))\n",
    "\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = data.coef_filter(Cc, features, require_both=True)\n",
    "    desc = data.coef_to_human(values, labels)\n",
    "    print(\"Class {}: {}\\n\".format(class_, desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00909e2ca2a2b852db835b984c01db5d56b3a1ad7fadd03544b4638cf5bc5640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
