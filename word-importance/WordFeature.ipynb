{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import os.path\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s] %(name)s: %(message)s\")\n",
    "\n",
    "import compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_study_prepared = \"studydata.pickle\"\n",
    "\n",
    "if not os.path.exists(fn_study_prepared):\n",
    "    df_study1, df_study2 = compute.prepare_study_data()\n",
    "\n",
    "    with open(fn_study_prepared, \"wb\") as fp:\n",
    "        pickle.dump(df_study1, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(df_study2, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(fn_study_prepared, \"rb\") as fp:\n",
    "    df_study1 = pickle.load(fp)\n",
    "    df_study2 = pickle.load(fp)\n",
    "\n",
    "df_study1, df_study2 = compute.clean_study_data(df_study1, df_study2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study1[[\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\"]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study2[[\"power\", \"dominance\", \"prestige\", \"workplace_power\", \"power_f\", \"dominance_f\", \"prestige_f\", \"workplace_power_f\"]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = \"power\"\n",
    "\n",
    "print(what, end=\":\\n\")\n",
    "print(\"  min=\", df_study1[what].min())\n",
    "print(\"  max=\", df_study1[what].max())\n",
    "# quantiles (low / mid / hig)\n",
    "df_study1[[\"power\", \"dominance\", \"prestige\"]].quantile([0, 1/3, 2/3, 3/3])\n",
    "\n",
    "# normal hist\n",
    "#df_study1[\"power\"].hist()\n",
    "# by quantiles\n",
    "#(df_study1[\"power\"] / df_study1[\"power\"].abs().max()).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = \"power\"\n",
    "\n",
    "# by quantiles\n",
    "df_study1[what].hist()\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "q33 = df_study1[what].quantile(1/3)\n",
    "q66 = df_study1[what].quantile(2/3)\n",
    "plt.axvline(q33, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.text(q33*1.01, max_ylim*0.9, '{:.2f}'.format(q33))\n",
    "plt.axvline(q66, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.text(q66*1.01, max_ylim*0.9, '{:.2f}'.format(q66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "# _ = compute.get_lmh_quantiles_mask(df_study1, \"power\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study1_quants = df_study1[[\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\"]].quantile([1/3, 2/3])\n",
    "df_study1_quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study2_quants = df_study2[[\"power\", \"dominance\", \"prestige\", \"workplace_power\", \"power_f\", \"dominance_f\", \"prestige_f\", \"workplace_power_f\"]].quantile([1/3, 2/3])\n",
    "df_study2_quants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (\"NOUN\", \"PROPN\")\n",
    "#pos = (\"ADJ\",)\n",
    "#pos = (\"ADV\",)\n",
    "#pos = (\"VERB\",)\n",
    "# https://universaldependencies.org/u/pos/\n",
    "lemma = True\n",
    "relative = False\n",
    "total_occ_min = 10  # at least 10 occurences (summed)\n",
    "#total_occ_min = 5   # if ADJ then less words required\n",
    "\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    df_lmh = compute.make_word_freq_score_lmh_comparison_df(df_study1, what, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "    df_lmh.plot(kind=\"barh\")\n",
    "    plt.title(\"Words for '{}' for {}\".format(what.title(), \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = (0., 1/3)\n",
    "range_ = (1/3, 2/3)\n",
    "#range_ = (2/3, 1.)\n",
    "\n",
    "whats = (\"power\", \"dominance\", \"prestige\")\n",
    "whats = (\"power_f\", \"dominance_f\", \"prestige_f\")\n",
    "#whats = (\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\")\n",
    "relative = True\n",
    "\n",
    "df_h_pdp = compute.make_word_freq_score_pdp_comparison_df(df_study1, whats=whats, range_=range_, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "df_h_pdp.plot(kind=\"barh\")\n",
    "plt.title(\"Words for quantile {:.2f}-{:.2f} for {}\".format(*range_, \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = (2/3, 1.)\n",
    "relative = True\n",
    "whatss = [(\"power\", \"power_f\"), (\"dominance\", \"dominance_f\"), (\"prestige\", \"prestige_f\")]\n",
    "\n",
    "pos = (\"NOUN\", \"PROPN\")\n",
    "#pos = (\"ADJ\",)\n",
    "#pos = (\"ADV\",)\n",
    "pos = (\"VERB\",)\n",
    "total_occ_min = 10  # at least 10 occurences (summed)\n",
    "#total_occ_min = 5   # if ADJ then less words required\n",
    "\n",
    "for whats in whatss:\n",
    "    df_h_pdp = compute.make_word_freq_score_pdp_comparison_df(df_study1, whats=whats, range_=range_, pos=pos, lemma=lemma, relative=relative, total_occ_min=total_occ_min)\n",
    "    df_h_pdp.plot(kind=\"barh\")\n",
    "    plt.title(\"Words for quantile {:.2f}-{:.2f} for {}\".format(*range_, \", \".join(pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute.write_freqs_to_excel(df_study1, \"study1-output.xlsx\")\n",
    "compute.write_freqs_to_excel(df_study2, \"study2-output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute.generate_freqs_figures(df_study1, \"figures_study1\")\n",
    "compute.generate_freqs_figures(df_study2, \"figures_study2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(compute)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat = compute.train_prepare(df_study1)\n",
    "\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    clf = compute.train_model(df_study1, what, doc_term_mat=doc_term_mat)\n",
    "    coefs = clf.coef_.copy()\n",
    "\n",
    "    #coefs = compute.normalize_coefs(coefs)\n",
    "\n",
    "    coefs = coefs * np.linspace(-1, 1, len(clf.classes_))[:,np.newaxis]\n",
    "    coefs = coefs.sum(axis=0)\n",
    "\n",
    "    coefs = compute.normalize_coefs(coefs)\n",
    "\n",
    "    values, labels = compute.coef_filter(coefs, clf.feature_names_in_)\n",
    "    desc = compute.coef_to_human(values, labels)\n",
    "    print(what)\n",
    "    print(desc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat = compute.train_prepare(df_study1)\n",
    "for what in (\"power\", \"dominance\", \"prestige\"):\n",
    "    clf = compute.train_model(df_study1, what, doc_term_mat=doc_term_mat)\n",
    "    compute.write_coefs_to_excel(clf, what, fn_output=\"study1-coefs.xlsx\", require_both=True)\n",
    "\n",
    "doc_term_mat = compute.train_prepare(df_study2)\n",
    "for what in (\"power\", \"dominance\", \"prestige\", \"workplace_power\"):\n",
    "    clf = compute.train_model(df_study2, what, doc_term_mat=doc_term_mat)\n",
    "    compute.write_coefs_to_excel(clf, what, fn_output=\"study2-coefs.xlsx\", require_both=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_study1[\"text_spacy_doc_filtered\"]\n",
    "#doc_term_mat, features = compute.build_count_matrix(df_sub)\n",
    "doc_term_mat, features = compute.build_feature_matrix(df_sub, norm=\"l2\", use_idf=True)\n",
    "# doc_term_mat.toarray()\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import check_cv\n",
    "\n",
    "#clf = sklearn.linear_model.Lasso(alpha=0.1)\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "X = doc_term_mat\n",
    "y = df_study1[\"power\"].to_numpy()\n",
    "#y = y.astype(int)\n",
    "y = np.vectorize(round)(y)\n",
    "# to interval [0, 1]\n",
    "#y = (y - np.min(y)) / np.ptp(y)\n",
    "#y = y[:,np.newaxis]\n",
    "#plt.hist(y)\n",
    "\n",
    "# # test cross-validation splits (based on sklearn.linear_model.LogisticRegressionCV)\n",
    "# cv = check_cv(3, y, classifier=True)\n",
    "# folds = list(cv.split(X, y))\n",
    "# for train, test in folds:\n",
    "#     X_train = X[train]\n",
    "#     X_test = X[test]\n",
    "#     y_train = y[train]\n",
    "#     y_test = y[test]\n",
    "#     clf_f = sklearn.linear_model.LogisticRegression()\n",
    "#     clf_f.fit(X_train, y_train)\n",
    "#     print(\"train:\", clf_f.score(X_train, y_train))\n",
    "#     print(\"test: \", clf_f.score(X_test, y_test))\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n",
    "\n",
    "#np.sort(clf.coef_[np.where(clf.coef_ > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "C = clf.coef_\n",
    "print(\"\\ncoefficients:\")\n",
    "print(C)\n",
    "# C / C.sum(axis=0)\n",
    "\n",
    "# norm: [0, 1]\n",
    "#C = (C - np.min(C)) / np.ptp(C)\n",
    "# norm: [-1, 1]\n",
    "C = 2. * (C - np.min(C)) / np.ptp(C) - 1\n",
    "#C = C / 2.\n",
    "\n",
    "# print words\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    srt = np.argsort(np.abs(Cc))[::-1]\n",
    "    mask = np.abs(Cc) > 0.25\n",
    "    mask_srt = mask[srt]\n",
    "    mask_srt[10:] = False\n",
    "    labels_srt = np.array(features)[srt][mask_srt]\n",
    "    values_srt = np.array(Cc)[srt][mask_srt]\n",
    "    srt = np.argsort(values_srt)[::-1]\n",
    "    labels_srt = labels_srt[srt]\n",
    "    values_srt = values_srt[srt]\n",
    "    desc = \" + \".join(\"{:.2f}*'{}'\".format(val, lbl) for lbl, val in zip(labels_srt, values_srt))\n",
    "    #desc = \" + \".join(\"{:.2f}*'{}'\".format(val, labels[i]) for i, val in enumerate(Cc))\n",
    "    print(\"Class\", class_, \"=\", desc, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = clf.coef_\n",
    "C = compute.normalize_coefs(C)\n",
    "\n",
    "dfs_coefs = []\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = compute.coef_filter(Cc, features, require_both=False)\n",
    "    col_lbl = \"Class {:d}\".format(int(class_))\n",
    "    cols = pd.MultiIndex.from_tuples([(col_lbl, \"words\"), (col_lbl, \"coefs\")])\n",
    "    df_coef = pd.DataFrame.from_records(data=zip(labels, values), columns=cols)\n",
    "    dfs_coefs.append(df_coef)\n",
    "\n",
    "df_coefs = pd.concat(dfs_coefs, axis=1)\n",
    "#df_coefs.columns = pd.MultiIndex.from_tuples(itertools.chain.from_iterable(((\"Class {:d}\".format(int(class_)), \"words\"), (\"Class {:d}\".format(int(class_)), \"coefs\")) for class_ in clf.classes_))\n",
    "df_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "C = clf.coef_\n",
    "#print(\"\\ncoefficients:\")\n",
    "#print(C)\n",
    "# C / C.sum(axis=0)\n",
    "\n",
    "C = compute.normalize_coefs(C)\n",
    "\n",
    "# print words\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = compute.coef_filter(Cc, features, require_both=False)\n",
    "    desc = compute.coef_to_human(values, labels)\n",
    "    print(\"Class {}: {}\\n\".format(class_, desc))\n",
    "\n",
    "print(\"\\nfeature importance:\")\n",
    "for class_, Cc in zip(clf.classes_, C):\n",
    "    values, labels = compute.coef_filter(Cc, features, require_both=True)\n",
    "    desc = compute.coef_to_human(values, labels)\n",
    "    print(\"Class {}: {}\\n\".format(class_, desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
