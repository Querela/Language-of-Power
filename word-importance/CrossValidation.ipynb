{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import os.path\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.metrics import check_scoring, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, check_cv, KFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s] %(name)s: %(message)s\")\n",
    "\n",
    "import compute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koerner/privat/Language-of-Power/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO] compute: Clean study data ...\n"
     ]
    }
   ],
   "source": [
    "fn_study_prepared = \"studydata.pickle\"\n",
    "df_study1, df_study2 = compute.load_cached_data(fn_study_prepared)\n",
    "\n",
    "if False:\n",
    "    # fill missing columns\n",
    "    for col in set(df_study2.columns).difference(df_study1.columns):\n",
    "        df_study1.insert(len(df_study1.columns), col, None)\n",
    "\n",
    "    # stack together (columns need to be same)\n",
    "    cols = df_study2.columns.sort_values()\n",
    "    pd.concat([df_study1[cols], df_study2[cols]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y train/test data\n",
    "\n",
    "# X\n",
    "df_study1_text = df_study1[[compute.COL_TEXT, compute.COL_TEXT_SPACY, compute.COL_TEXT_SPACY_CLEAN]]\n",
    "df_study2_text = df_study2[[compute.COL_TEXT, compute.COL_TEXT_SPACY, compute.COL_TEXT_SPACY_CLEAN]]\n",
    "df_both_text = pd.concat([df_study1_text, df_study2_text], axis=0).reset_index(drop=True)\n",
    "\n",
    "# y\n",
    "df_study1_scores = df_study1[compute.COLS_SCORES]\n",
    "df_study2_scores = df_study2[compute.COLS_SCORES + compute.COLS_SCORES_S2]\n",
    "df_both_scores = pd.concat([df_study1_scores, df_study2_scores[compute.COLS_SCORES]], axis=0).reset_index(drop=True)\n",
    "\n",
    "# X\n",
    "df_study1_liwc = df_study1[compute.COLS_LIWC_REL]\n",
    "df_study2_liwc = df_study2[compute.COLS_LIWC_REL]\n",
    "df_both_liwc = pd.concat([df_study1_liwc, df_study2_liwc], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build standard document-term matrix\n",
    "\n",
    "def build_dtm_df(df_study, binarize=False):\n",
    "    df = df_study[compute.COL_TEXT_SPACY_CLEAN]\n",
    "    doc_term_mat, features = compute.build_feature_matrix(df, norm=\"l2\", use_idf=True)\n",
    "\n",
    "    # binarize (0/1 instead of floats)\n",
    "    if binarize:\n",
    "        doc_term_mat = np.array(np.vectorize(round)(doc_term_mat.todense()))\n",
    "    else:\n",
    "        doc_term_mat = doc_term_mat.toarray()\n",
    "\n",
    "    return pd.DataFrame(doc_term_mat, columns=features)\n",
    "\n",
    "\n",
    "binarize = False\n",
    "# X\n",
    "df_study1_dtm = build_dtm_df(df_study1_text, binarize=binarize)\n",
    "df_study2_dtm = build_dtm_df(df_study2_text, binarize=binarize)\n",
    "df_both_dtm = build_dtm_df(df_both_text, binarize=binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale LIWC values into [0, 1] range, per column\n",
    "\n",
    "def scale_liwc_df(df_study):\n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "\n",
    "    scaler.fit(df_study[compute.COLS_LIWC_REL])\n",
    "    scaler.feature_names_in_\n",
    "    #scaler.scale_, scaler.mean_  # StandardScaler\n",
    "\n",
    "    data = scaler.transform(df_study[compute.COLS_LIWC_REL])\n",
    "    return pd.DataFrame(data, columns=scaler.feature_names_in_)\n",
    "\n",
    "\n",
    "# X\n",
    "df_study1_liwc_scaled = scale_liwc_df(df_study1_liwc)\n",
    "df_study2_liwc_scaled = scale_liwc_df(df_study2_liwc)\n",
    "df_both_liwc_scaled = scale_liwc_df(df_both_liwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse variables into three classes (low/mid/high) based on quantiles\n",
    "\n",
    "def quantize_scores(scores, as_str=False):\n",
    "    # split by quantiles into 3 parts\n",
    "    q33 = np.quantile(scores, 1 / 3)\n",
    "    q66 = np.quantile(scores, 2 / 3)\n",
    "\n",
    "    idx = np.digitize(scores, [q33, q66], right=True)\n",
    "\n",
    "    # validate\n",
    "    # assert all([\n",
    "    #     v <= q33 if x == 0 else v > q33 and v <= q66 if x == 1 else v > q66\n",
    "    #     for v, x in [(scores[i], x) for i, x in enumerate(idx)]\n",
    "    # ])\n",
    "\n",
    "    if not as_str:\n",
    "        return idx\n",
    "\n",
    "    # map to class labels\n",
    "    return np.vectorize({0: \"low\", 1: \"mid\", 2: \"high\"}.get)(idx)\n",
    "\n",
    "\n",
    "def quantize_score_df(df_scores, cols, as_str=False):\n",
    "    all_scores = dict()\n",
    "    for col in cols:\n",
    "        all_scores[col] = quantize_scores(df_scores[col], as_str=as_str)\n",
    "    return pd.DataFrame.from_dict(all_scores)\n",
    "\n",
    "\n",
    "as_str = False\n",
    "# y\n",
    "df_study1_scores_cls = quantize_score_df(df_study1_scores, compute.COLS_SCORES, as_str=as_str)\n",
    "df_study2_scores_cls = quantize_score_df(df_study2_scores, compute.COLS_SCORES + compute.COLS_SCORES_S2, as_str=as_str)\n",
    "df_both_scores_cls = quantize_score_df(df_both_scores, compute.COLS_SCORES, as_str=as_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifiers / Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sels_data = [\"DTM\", \"LIWC\", \"LIWC_S\", \"B\", \"B_S\"]\n",
    "sels_study = [\"S1\", \"S2\", \"S1+S2\"]\n",
    "sels_var = [\"power\", \"dominance\", \"prestige\", \"power_f\", \"dominance_f\", \"prestige_f\"]\n",
    "\n",
    "\n",
    "def select_data(sel_data, sel_study):\n",
    "    df_dtm = None\n",
    "    if sel_data == \"DTM\":\n",
    "        if sel_study == \"S1\":\n",
    "            df_dtm = df_study1_dtm\n",
    "        elif sel_study == \"S2\":\n",
    "            df_dtm = df_study2_dtm\n",
    "        elif sel_study == \"S1+S2\":\n",
    "            df_dtm = df_both_dtm\n",
    "    elif sel_data == \"LIWC\":\n",
    "        if sel_study == \"S1\":\n",
    "            df_dtm = df_study1_liwc\n",
    "        elif sel_study == \"S2\":\n",
    "            df_dtm = df_study2_liwc\n",
    "        elif sel_study == \"S1+S2\":\n",
    "            df_dtm = df_both_liwc\n",
    "    elif sel_data == \"LIWC_S\":\n",
    "        if sel_study == \"S1\":\n",
    "            df_dtm = df_study1_liwc_scaled\n",
    "        elif sel_study == \"S2\":\n",
    "            df_dtm = df_study2_liwc_scaled\n",
    "        elif sel_study == \"S1+S2\":\n",
    "            df_dtm = df_both_liwc_scaled\n",
    "    elif sel_data == \"B\":\n",
    "        if sel_study == \"S1\":\n",
    "            df_dtm = pd.concat([df_study1_dtm, df_study1_liwc], axis=1)\n",
    "        elif sel_study == \"S2\":\n",
    "            df_dtm = pd.concat([df_study2_dtm, df_study2_liwc], axis=1)\n",
    "        elif sel_study == \"S1+S2\":\n",
    "            df_dtm = pd.concat([df_both_dtm, df_both_liwc], axis=1)\n",
    "    elif sel_data == \"B_S\":\n",
    "        if sel_study == \"S1\":\n",
    "            df_dtm = pd.concat([df_study1_dtm, df_study1_liwc_scaled], axis=1)\n",
    "        elif sel_study == \"S2\":\n",
    "            df_dtm = pd.concat([df_study2_dtm, df_study2_liwc_scaled], axis=1)\n",
    "        elif sel_study == \"S1+S2\":\n",
    "            df_dtm = pd.concat([df_both_dtm, df_both_liwc_scaled], axis=1)\n",
    "    assert df_dtm is not None\n",
    "    return df_dtm\n",
    "\n",
    "\n",
    "def select_scores(sel_study, sel_var):\n",
    "    df_scores = None\n",
    "    if sel_study == \"S1\":\n",
    "        df_scores = df_study1_scores\n",
    "    elif sel_study == \"S2\":\n",
    "        df_scores = df_study2_scores\n",
    "    elif sel_study == \"S1+S2\":\n",
    "        df_scores = df_both_scores\n",
    "    assert df_scores is not None\n",
    "    col = f\"s:{sel_var}\"\n",
    "    assert col in df_scores.columns\n",
    "    return df_scores[col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials(X, y, clf, p_grid, num_trials):\n",
    "    scores = np.zeros(num_trials)\n",
    "    params = []\n",
    "\n",
    "    # Loop for each trial\n",
    "    for i in range(num_trials):\n",
    "        # cross-validation techniques for the inner and outer loops\n",
    "        # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "        inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "        # Non_nested parameter search and scoring\n",
    "        # clf_gs = GridSearchCV(estimator=clf, param_grid=p_grid, cv=outer_cv)\n",
    "        # clf_gs.fit(X, y)\n",
    "        # clf.cv_results_\n",
    "\n",
    "        # Nested CV with parameter optimization\n",
    "        clf_gs = GridSearchCV(estimator=clf, param_grid=p_grid, cv=inner_cv, verbose=0)\n",
    "        #score = cross_val_score(clf_gs, X=X, y=y, cv=outer_cv)\n",
    "\n",
    "        scorer = check_scoring(clf_gs, scoring=None)\n",
    "        cv_results = cross_validate(\n",
    "            estimator=clf_gs,\n",
    "            X=X,\n",
    "            y=y,\n",
    "            scoring={\"score\": scorer},\n",
    "            cv=outer_cv,\n",
    "            return_estimator=True\n",
    "        )\n",
    "        score = cv_results[\"test_score\"]\n",
    "        best_params = cv_results[\"estimator\"][score.argmax()].best_params_\n",
    "\n",
    "        scores[i] = score.mean()\n",
    "        params.append(best_params)\n",
    "\n",
    "    return scores, params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_study = \"S1+S2\"  # one of: S1, S2, S1+S2\n",
    "sel_data = \"B\"       # one of: DTM, LIWC, LIWC_S, B (DTM, LIWC), B_S (DTM, LIWC_S)\n",
    "sel_var = \"power\"    # one of: power, dominance, prestige, power_f, dominance_f, prestige_f\n",
    "\n",
    "X = select_data(sel_data, sel_study).values\n",
    "y = select_scores(sel_study, sel_var)\n",
    "\n",
    "# convert continuous y variable to class variable\n",
    "#y_cls = y.round()\n",
    "#y_cls = y.astype(int)\n",
    "y_cls = np.vectorize(round)(y)\n",
    "y_lmh = quantize_scores(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 1, 'gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.375</th>\n",
       "      <th>0.370</th>\n",
       "      <th>0.360</th>\n",
       "      <th>0.345</th>\n",
       "      <th>0.355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.375  0.370  0.360  0.345  0.355\n",
       "C        1.0    1.0   10.0    1.0    1.0\n",
       "gamma    0.1    0.1    0.1    0.1    0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel=\"rbf\")\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "scores, params = run_trials(X, y_cls, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 1, 'gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.3825</th>\n",
       "      <th>0.3825</th>\n",
       "      <th>0.3275</th>\n",
       "      <th>0.3825</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.3825  0.3825  0.3275  0.3825\n",
       "C       10.00    1.00    1.00     1.0\n",
       "gamma    0.01    0.01    0.01     0.1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.svm.SVC(kernel=\"rbf\")\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "scores, params = run_trials(X, y_lmh, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 0.01, 'max_iter': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.300</th>\n",
       "      <th>0.280</th>\n",
       "      <th>0.245</th>\n",
       "      <th>0.265</th>\n",
       "      <th>0.230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.300  0.280  0.245  0.265  0.230\n",
       "C          0.01      1   0.01    0.1    0.1\n",
       "max_iter  10.00     10  10.00   10.0   10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "p_grid = {\"C\": [1, 0.1, 0.01], \"max_iter\": [10, 100, 500]}\n",
    "\n",
    "scores, params = run_trials(X, y_cls, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'C': 1, 'max_iter': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.3700</th>\n",
       "      <th>0.3550</th>\n",
       "      <th>0.4150</th>\n",
       "      <th>0.3975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.3700  0.3550  0.4150  0.3975\n",
       "C              1       1       1     0.1\n",
       "max_iter     100     100     100    10.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(solver=\"liblinear\")\n",
    "p_grid = {\"C\": [1, 0.1, 0.01], \"max_iter\": [10, 100, 500]}\n",
    "\n",
    "scores, params = run_trials(X, y_lmh, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'alpha': 10, 'max_iter': 250}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.050571</th>\n",
       "      <th>-0.003739</th>\n",
       "      <th>-0.031928</th>\n",
       "      <th>-0.001635</th>\n",
       "      <th>-0.075270</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          -0.050571  -0.003739  -0.031928  -0.001635  -0.075270\n",
       "alpha            10         10         10         10         10\n",
       "max_iter        250        250        250        250        250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.Lasso(selection=\"random\")\n",
    "p_grid = {\"alpha\": [10, 1, 0.1, 0.01], \"max_iter\": [250, 1000, 5000]}\n",
    "\n",
    "scores, params = run_trials(X, y, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'alpha': 10, 'max_iter': 250}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.018485</th>\n",
       "      <th>-0.027791</th>\n",
       "      <th>-0.016605</th>\n",
       "      <th>-0.007605</th>\n",
       "      <th>-0.001174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          -0.018485  -0.027791  -0.016605  -0.007605  -0.001174\n",
       "alpha            10         10         10         10         10\n",
       "max_iter        250        250        250        250        250"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this might not be best, we do some linear model but with classes?\n",
    "\n",
    "clf = sklearn.linear_model.Lasso(selection=\"random\")\n",
    "p_grid = {\"alpha\": [10, 1, 0.1, 0.01], \"max_iter\": [250, 1000, 5000]}\n",
    "\n",
    "scores, params = run_trials(X, y_lmh, clf, p_grid, 5)\n",
    "\n",
    "print(\"best params: \", params[scores.argmax()])\n",
    "pd.DataFrame.from_dict(dict(zip(scores, params)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ----------------------------------------\n",
      "# Running for Study: S1+S2 ...\n",
      "## Running for Variable: ***[[power]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 10, 'gamma': 0.1} @ 0.375000 ±0.022215\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.367500 ±0.019144\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003178 ±0.006021\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.357500 ±0.010173\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 100} @ 0.332500 ±0.021829\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.009783 ±0.010780\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.357500 ±0.014832\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.370000 ±0.029326\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.026360 ±0.013039\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.357500 ±0.010173\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.342500 ±0.024829\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.009794 ±0.010783\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 100, 'gamma': 0.01} @ 0.342500 ±0.011979\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.365000 ±0.026907\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.026362 ±0.013037\n",
      "\n",
      "## Running for Variable: ***[[dominance]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.355000 ±0.014883\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.347500 ±0.010173\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.005442 ±0.009491\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.355000 ±0.016508\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 100} @ 0.332500 ±0.009798\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008403\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.360000 ±0.015166\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.340000 ±0.019196\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008464\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.355000 ±0.016508\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.345000 ±0.013657\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008403\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.357500 ±0.014457\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.330000 ±0.018615\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008464\n",
      "\n",
      "## Running for Variable: ***[[prestige]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.497500 ±0.005000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.497500 ±0.002000\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.000597 ±0.009936\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.497500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.437500 ±0.015297\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.035034 ±0.007923\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.497500 ±0.011979\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.420000 ±0.013874\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.016266 ±0.010811\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.497500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.440000 ±0.015572\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.035087 ±0.007931\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.497500 ±0.010886\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.420000 ±0.013874\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.016274 ±0.010811\n",
      "\n",
      "## Running for Variable: ***[[power_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.427500 ±0.016000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.427500 ±0.002000\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001951 ±0.012982\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.427500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.402500 ±0.011554\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.043876 ±0.013916\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.432500 ±0.010368\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.385000 ±0.020248\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.059039 ±0.012957\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.427500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.402500 ±0.013191\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.043907 ±0.013918\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.1} @ 0.432500 ±0.011247\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.390000 ±0.021943\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.059042 ±0.012956\n",
      "\n",
      "## Running for Variable: ***[[dominance_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.447500 ±0.016386\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.1, 'max_iter': 10} @ 0.432500 ±0.013191\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003755 ±0.010660\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.432500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.402500 ±0.020000\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.010348 ±0.021743\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 10, 'gamma': 0.1} @ 0.445000 ±0.015297\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.390000 ±0.019975\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.024463 ±0.010318\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.432500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.405000 ±0.020000\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.010405 ±0.021801\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 10, 'gamma': 0.1} @ 0.442500 ±0.013928\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.387500 ±0.013730\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.024462 ±0.010420\n",
      "\n",
      "## Running for Variable: ***[[prestige_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 10, 'gamma': 0.1} @ 0.610000 ±0.004472\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.607500 ±0.000000\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001399 ±0.011015\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.607500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 100} @ 0.562500 ±0.008216\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.144124 ±0.016906\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.615000 ±0.003873\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.577500 ±0.014748\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.01, 'max_iter': 1000, 'selection': 'random'} @ 0.092794 ±0.014771\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.607500 ±0.000000\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 100} @ 0.572500 ±0.009925\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.144088 ±0.016713\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Clf: SVC()\n",
      "     best params: {'C': 1, 'gamma': 0.01} @ 0.615000 ±0.003742\n",
      "#### Clf: LogisticRegression(solver='liblinear')\n",
      "     best params: {'C': 0.01, 'max_iter': 10} @ 0.570000 ±0.012981\n",
      "#### Regr: Lasso()\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'random'} @ 0.092796 ±0.014759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfs = [\n",
    "    (sklearn.svm.SVC(kernel=\"rbf\"),\n",
    "     {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}),\n",
    "    (sklearn.linear_model.LogisticRegression(solver=\"liblinear\"),\n",
    "     {\"C\": [1, 0.1, 0.01], \"max_iter\": [10, 100, 500]}),\n",
    "]\n",
    "regrs = [\n",
    "    (sklearn.linear_model.Lasso(),\n",
    "     {\"alpha\": [10, 1, 0.1, 0.01], \"max_iter\": [250, 1000, 5000], \"selection\": [\"cyclic\", \"random\"]}),\n",
    "]\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for sel_study in sels_study:\n",
    "    results[sel_study] = dict()\n",
    "    print(\"#\", \"-\" * 40)\n",
    "    print(f\"# Running for Study: {sel_study} ...\")\n",
    "    for sel_var in sels_var:\n",
    "        results[sel_study][sel_var] = dict()\n",
    "        print(f\"## Running for Variable: ***[[{sel_var}]]*** ...\")\n",
    "        for sel_data in sels_data:\n",
    "            results[sel_study][sel_var][sel_data] = dict()\n",
    "            print(f\"### Running on Data: {sel_data} ...\")\n",
    "\n",
    "            # data\n",
    "            X = select_data(sel_data, sel_study).values\n",
    "            y = select_scores(sel_study, sel_var)\n",
    "            y_cls = np.vectorize(round)(y)\n",
    "\n",
    "            # clf\n",
    "            for clf, p_grid in clfs:\n",
    "                print(f\"#### Clf: {clf}\")\n",
    "                scores, params = run_trials(X, y_cls, clf, p_grid, 5)\n",
    "                print(f\"     best params: {params[scores.argmax()]} @ {scores.max():f} ±{scores.std():f}\")\n",
    "                results[sel_study][sel_var][sel_data][clf.__class__.__name__.rsplit(\".\", 1)[-1]] = pd.DataFrame.from_dict(dict(zip(scores, params)))\n",
    "\n",
    "            # regr\n",
    "            for reg, p_grid in regrs:\n",
    "                print(f\"#### Regr: {reg}\")\n",
    "                scores, params = run_trials(X, y, reg, p_grid, 5)\n",
    "                print(f\"     best params: {params[scores.argmax()]} @ {scores.max():f} ±{scores.std():f}\")\n",
    "                results[sel_study][sel_var][sel_data][reg.__class__.__name__.rsplit(\".\", 1)[-1]] = pd.DataFrame.from_dict(dict(zip(scores, params)))\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_results = \"results.pickle\"\n",
    "if not os.path.exists(fn_results):\n",
    "    with open(fn_results, \"wb\") as fp:\n",
    "        pickle.dump(results, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(fn_results, \"rb\") as fp:\n",
    "    results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ----------------------------------------\n",
      "# Running for Study: S1 ...\n",
      "## Running for Variable: ***[[power]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.375000 ±0.026192\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.375000 ±0.019900\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 5000, 'selection': 'random'} @ -0.001360 ±0.029390\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.375000 ±0.002357\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 100.0} @ 0.290000 ±0.011456\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.019622 ±0.029883\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.380000 ±0.012083\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.295000 ±0.030757\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001635 ±0.028057\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.375000 ±0.002357\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 100.0} @ 0.295000 ±0.016956\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.019601 ±0.029878\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.375000 ±0.010677\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.300000 ±0.024779\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001635 ±0.028057\n",
      "\n",
      "## Running for Variable: ***[[dominance]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.305000 ±0.024109\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.260000 ±0.009274\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.011175 ±0.015611\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.310000 ±0.033796\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 100} @ 0.280000 ±0.022000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.010457 ±0.014596\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.01} @ 0.315000 ±0.036818\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.270000 ±0.022185\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.009470 ±0.016074\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.310000 ±0.033796\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 100} @ 0.275000 ±0.021937\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.010457 ±0.014596\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.01} @ 0.300000 ±0.028107\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.275000 ±0.021307\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.009470 ±0.016074\n",
      "\n",
      "## Running for Variable: ***[[prestige]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.485000 ±0.005000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.485000 ±0.000000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 5000, 'selection': 'random'} @ -0.003426 ±0.015386\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.485000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.445000 ±0.033971\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.010957 ±0.019881\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.505000 ±0.029439\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.395000 ±0.016008\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.008638 ±0.024615\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.485000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.445000 ±0.037815\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.010958 ±0.019955\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.505000 ±0.032156\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.395000 ±0.015411\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.008638 ±0.024615\n",
      "\n",
      "## Running for Variable: ***[[power_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.385000 ±0.027857\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.395000 ±0.033257\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 1000, 'selection': 'random'} @ -0.007869 ±0.014136\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.385000 ±0.034238\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.340000 ±0.028000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.037772 ±0.033346\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.380000 ±0.026926\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.290000 ±0.013123\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ -0.002123 ±0.016018\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.385000 ±0.034238\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.340000 ±0.026192\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.037808 ±0.033345\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.380000 ±0.028566\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.280000 ±0.011402\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ -0.002114 ±0.016024\n",
      "\n",
      "## Running for Variable: ***[[dominance_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.420000 ±0.030757\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.410000 ±0.008124\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 5000, 'selection': 'random'} @ -0.006658 ±0.013338\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.400000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.345000 ±0.019647\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.006567 ±0.012871\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.405000 ±0.030430\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.350000 ±0.024495\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ -0.002469 ±0.016662\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.400000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.350000 ±0.021213\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.006567 ±0.012871\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.405000 ±0.028705\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.355000 ±0.026000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ -0.002467 ±0.016662\n",
      "\n",
      "## Running for Variable: ***[[prestige_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.570000 ±0.006236\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.560000 ±0.000000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003361 ±0.020323\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.560000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.510000 ±0.010801\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.099812 ±0.017417\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.580000 ±0.009274\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.460000 ±0.018371\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.121974 ±0.011749\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.560000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.510000 ±0.008498\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.099852 ±0.017421\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.580000 ±0.009274\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.460000 ±0.016724\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.121986 ±0.011755\n",
      "\n",
      "# ----------------------------------------\n",
      "# Running for Study: S2 ...\n",
      "## Running for Variable: ***[[power]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.375000 ±0.022045\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.375000 ±0.012410\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'cyclic'} @ -0.004185 ±0.042992\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.390000 ±0.019526\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.325000 ±0.018815\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.004185 ±0.042254\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.375000 ±0.018601\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.340000 ±0.023875\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003202 ±0.035638\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.390000 ±0.019526\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.325000 ±0.016852\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.004185 ±0.042254\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.375000 ±0.018371\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.340000 ±0.023152\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003203 ±0.035640\n",
      "\n",
      "## Running for Variable: ***[[dominance]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.365000 ±0.015166\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.375000 ±0.019339\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'cyclic'} @ -0.018157 ±0.013030\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.405000 ±0.034409\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.415000 ±0.018371\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.018288 ±0.019947\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.375000 ±0.020833\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.370000 ±0.022226\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.039191 ±0.010755\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.405000 ±0.034409\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.420000 ±0.020548\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.018288 ±0.019952\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.390000 ±0.018330\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.380000 ±0.022891\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.039192 ±0.010754\n",
      "\n",
      "## Running for Variable: ***[[prestige]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.510000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.510000 ±0.015456\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.019554 ±0.061176\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.510000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.425000 ±0.026071\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.055910 ±0.076500\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.505000 ±0.015562\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.430000 ±0.034986\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.005336 ±0.066582\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.510000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.425000 ±0.023367\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.055971 ±0.076495\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.505000 ±0.020138\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.430000 ±0.032596\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.005342 ±0.066586\n",
      "\n",
      "## Running for Variable: ***[[power_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.470000 ±0.012247\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.470000 ±0.004714\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.005932 ±0.019277\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.470000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.430000 ±0.022450\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ -0.006207 ±0.021089\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.470000 ±0.020117\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.440000 ±0.027092\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.007658 ±0.017074\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.470000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.430000 ±0.025020\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ -0.006216 ±0.021087\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.470000 ±0.018371\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.435000 ±0.020591\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.007657 ±0.017093\n",
      "\n",
      "## Running for Variable: ***[[dominance_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 100.0, 'gamma': 0.01} @ 0.510000 ±0.051536\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.485000 ±0.042544\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001310 ±0.021467\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.465000 ±0.035014\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 100.0} @ 0.445000 ±0.022494\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ -0.005581 ±0.029851\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.01} @ 0.530000 ±0.055534\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.445000 ±0.020248\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.020842 ±0.025842\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.465000 ±0.035014\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.445000 ±0.021213\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ -0.005580 ±0.029855\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.01} @ 0.515000 ±0.031401\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.455000 ±0.019494\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.020818 ±0.025918\n",
      "\n",
      "## Running for Variable: ***[[prestige_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.655000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.655000 ±0.000000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.008781 ±0.009376\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.655000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.605000 ±0.013463\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'cyclic'} @ -0.010823 ±0.030416\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.655000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.520000 ±0.014337\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.000614 ±0.014233\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.655000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.605000 ±0.012437\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ -0.010814 ±0.030400\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.655000 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.530000 ±0.018708\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.000604 ±0.014244\n",
      "\n",
      "# ----------------------------------------\n",
      "# Running for Study: S1+S2 ...\n",
      "## Running for Variable: ***[[power]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.375000 ±0.022215\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.367500 ±0.019144\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003178 ±0.006021\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.357500 ±0.010173\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 100.0} @ 0.332500 ±0.021829\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.009783 ±0.010780\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.357500 ±0.016346\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.370000 ±0.029326\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.026360 ±0.013039\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.357500 ±0.010173\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.342500 ±0.024829\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.009794 ±0.010783\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 100.0, 'gamma': 0.01} @ 0.342500 ±0.011979\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.365000 ±0.026907\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 1000, 'selection': 'random'} @ 0.026362 ±0.013037\n",
      "\n",
      "## Running for Variable: ***[[dominance]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.355000 ±0.014883\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.347500 ±0.011371\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.005442 ±0.009491\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.355000 ±0.016441\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 100.0} @ 0.332500 ±0.010514\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008403\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.360000 ±0.015166\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.340000 ±0.019196\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008464\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.355000 ±0.016441\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.345000 ±0.013657\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008403\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.357500 ±0.014457\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.330000 ±0.018615\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.007215 ±0.008464\n",
      "\n",
      "## Running for Variable: ***[[prestige]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.497500 ±0.005893\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.497500 ±0.002357\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.000597 ±0.009936\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.497500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.437500 ±0.015297\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.035034 ±0.007923\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.497500 ±0.013035\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.420000 ±0.013874\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.016266 ±0.010811\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.497500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.440000 ±0.016489\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 250, 'selection': 'random'} @ 0.035087 ±0.007931\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.497500 ±0.010886\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.420000 ±0.013874\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.016274 ±0.010811\n",
      "\n",
      "## Running for Variable: ***[[power_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.427500 ±0.015456\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.427500 ±0.002500\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001951 ±0.012982\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.427500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.402500 ±0.011554\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.043876 ±0.013916\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.432500 ±0.010807\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.385000 ±0.020248\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.059039 ±0.012957\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.427500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.402500 ±0.013191\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.043907 ±0.013918\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.1} @ 0.432500 ±0.011247\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.390000 ±0.024012\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.059042 ±0.012956\n",
      "\n",
      "## Running for Variable: ***[[dominance_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.447500 ±0.016386\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.1, 'max_iter': 10.0} @ 0.432500 ±0.015456\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'cyclic'} @ -0.003755 ±0.010660\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.432500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.402500 ±0.020000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 1000, 'selection': 'random'} @ 0.010348 ±0.021743\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.445000 ±0.015297\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.390000 ±0.019975\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 5000, 'selection': 'random'} @ 0.024463 ±0.010318\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.432500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.405000 ±0.020000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 1, 'max_iter': 5000, 'selection': 'random'} @ 0.010405 ±0.021801\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.442500 ±0.013928\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.387500 ±0.013730\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'random'} @ 0.024462 ±0.010420\n",
      "\n",
      "## Running for Variable: ***[[prestige_f]]*** ...\n",
      "### Running on Data: DTM ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 10.0, 'gamma': 0.1} @ 0.610000 ±0.004801\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 1, 'max_iter': 10} @ 0.607500 ±0.000000\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 10, 'max_iter': 250, 'selection': 'cyclic'} @ -0.001399 ±0.011015\n",
      "\n",
      "### Running on Data: LIWC ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.607500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 100.0} @ 0.562500 ±0.008216\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.144124 ±0.016906\n",
      "\n",
      "### Running on Data: LIWC_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.615000 ±0.004249\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.577500 ±0.014748\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 1000, 'selection': 'random'} @ 0.092794 ±0.014771\n",
      "\n",
      "### Running on Data: B ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.607500 ±0.000000\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 100.0} @ 0.572500 ±0.009925\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.1, 'max_iter': 250, 'selection': 'cyclic'} @ 0.144088 ±0.016713\n",
      "\n",
      "### Running on Data: B_S ...\n",
      "#### Estimator: SVC\n",
      "     best params: {'C': 1.0, 'gamma': 0.01} @ 0.615000 ±0.003698\n",
      "#### Estimator: LogisticRegression\n",
      "     best params: {'C': 0.01, 'max_iter': 10.0} @ 0.570000 ±0.012981\n",
      "#### Estimator: Lasso\n",
      "     best params: {'alpha': 0.01, 'max_iter': 250, 'selection': 'random'} @ 0.092796 ±0.014759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sel_study in sels_study:\n",
    "    print(\"#\", \"-\" * 40)\n",
    "    print(f\"# Running for Study: {sel_study} ...\")\n",
    "    for sel_var in sels_var:\n",
    "        print(f\"## Running for Variable: ***[[{sel_var}]]*** ...\")\n",
    "        for sel_data in sels_data:\n",
    "            print(f\"### Running on Data: {sel_data} ...\")\n",
    "\n",
    "            for est, df in results[sel_study][sel_var][sel_data].items():\n",
    "                print(f\"#### Estimator: {est}\")\n",
    "                scores = df.columns.values\n",
    "                best_params = df.iloc[:,scores.argmax()].to_dict()\n",
    "                print(f\"     best params: {best_params} @ {scores.max():f} ±{scores.std():f}\")\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in Data from Study: S1\n",
      "  Best results for >>>power<<< on data: 'LIWC' with 0.373333\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.375000 ±0.002357\n",
      "\n",
      "  Best results for >>>dominance<<< on data: 'LIWC_S' with 0.268333\n",
      "  -> Clf: SVC with params: {'C': 10.0, 'gamma': 0.01}; 0.315000 ±0.036818\n",
      "\n",
      "  Best results for >>>prestige<<< on data: 'DTM' with 0.485000\n",
      "  -> Clf: LogisticRegression with params: {'C': 0.1, 'max_iter': 10.0}; 0.485000 ±0.000000\n",
      "\n",
      "  Best results for >>>power_f<<< on data: 'DTM' with 0.363000\n",
      "  -> Clf: LogisticRegression with params: {'C': 1, 'max_iter': 10}; 0.395000 ±0.033257\n",
      "\n",
      "  Best results for >>>dominance_f<<< on data: 'LIWC' with 0.400000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.400000 ±0.000000\n",
      "\n",
      "  Best results for >>>prestige_f<<< on data: 'LIWC_S' with 0.572000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.580000 ±0.009274\n",
      "\n",
      "Results in Data from Study: S2\n",
      "  Best results for >>>power<<< on data: 'DTM' with 0.361000\n",
      "  -> Clf: LogisticRegression with params: {'C': 1, 'max_iter': 10}; 0.375000 ±0.012410\n",
      "\n",
      "  Best results for >>>dominance<<< on data: 'B' with 0.393333\n",
      "  -> Clf: LogisticRegression with params: {'C': 0.1, 'max_iter': 10.0}; 0.420000 ±0.020548\n",
      "\n",
      "  Best results for >>>prestige<<< on data: 'DTM' with 0.510000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.510000 ±0.000000\n",
      "\n",
      "  Best results for >>>power_f<<< on data: 'LIWC' with 0.470000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.470000 ±0.000000\n",
      "\n",
      "  Best results for >>>dominance_f<<< on data: 'B_S' with 0.457000\n",
      "  -> Clf: SVC with params: {'C': 10.0, 'gamma': 0.01}; 0.515000 ±0.031401\n",
      "\n",
      "  Best results for >>>prestige_f<<< on data: 'DTM' with 0.655000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.655000 ±0.000000\n",
      "\n",
      "Results in Data from Study: S1+S2\n",
      "  Best results for >>>power<<< on data: 'LIWC' with 0.342000\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.357500 ±0.010173\n",
      "\n",
      "  Best results for >>>dominance<<< on data: 'LIWC' with 0.336250\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.1}; 0.355000 ±0.016441\n",
      "\n",
      "  Best results for >>>prestige<<< on data: 'LIWC' with 0.497500\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.497500 ±0.000000\n",
      "\n",
      "  Best results for >>>power_f<<< on data: 'LIWC' with 0.427500\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.427500 ±0.000000\n",
      "\n",
      "  Best results for >>>dominance_f<<< on data: 'LIWC' with 0.432500\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.432500 ±0.000000\n",
      "\n",
      "  Best results for >>>prestige_f<<< on data: 'LIWC_S' with 0.610833\n",
      "  -> Clf: SVC with params: {'C': 1.0, 'gamma': 0.01}; 0.615000 ±0.004249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sel_study in sels_study:\n",
    "    print(f\"Results in Data from Study: {sel_study}\")\n",
    "\n",
    "    for sel_var in sels_var:\n",
    "        best = None\n",
    "        for sel_data in sels_data:\n",
    "            for clf, clf_results in results[sel_study][sel_var][sel_data].items():\n",
    "                scores = clf_results.columns.values\n",
    "                score = scores.mean()\n",
    "                if best is None or score > best[0]:\n",
    "                    best = (score, clf_results, clf, sel_data)\n",
    "        print(f\"  Best results for >>>{sel_var}<<< on data: '{best[3]}' with {best[0]:f}\")\n",
    "        scores = best[1].columns.values\n",
    "        best_params = best[1].iloc[:,scores.argmax()].to_dict()\n",
    "        print(f\"  -> Clf: {best[2]} with params: {best_params}; {scores.max():f} ±{scores.std():f}\")\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'C': 1, 'gamma': 0.01} with 0.335000 (0.318000 ±0.014353)\n",
      "train cross-validation score: 0.355000\n",
      "R² Score train: 1.0, test: -1.36972276544346\n",
      "Accuracy Score train: 1.0, test: 0.355\n"
     ]
    }
   ],
   "source": [
    "sel_data = \"LIWC\"       # one of: DTM, LIWC, LIWC_S, B (DTM, LIWC), B_S (DTM, LIWC_S)\n",
    "sel_var = \"prestige\"    # one of: power, dominance, prestige, power_f, dominance_f, prestige_f\n",
    "\n",
    "X = select_data(sel_data, \"S2\").values\n",
    "y = select_scores(\"S2\", sel_var)\n",
    "y_cls = quantize_scores(y)\n",
    "\n",
    "X1 = select_data(sel_data, \"S1\").values\n",
    "y1 = select_scores(\"S1\", sel_var)\n",
    "y1_cls = quantize_scores(y1)\n",
    "\n",
    "clf = sklearn.svm.SVC(kernel=\"rbf\")\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "scores, params = run_trials(X, y_cls, clf, p_grid, 5)\n",
    "best_params = params[scores.argmax()]\n",
    "\n",
    "print(f\"best params: {best_params} with {scores.max():f} ({scores.mean():f} ±{scores.std():f})\")\n",
    "\n",
    "clf.set_params(**best_params)\n",
    "clf.fit(X, y_cls)\n",
    "score = clf.score(X1, y1_cls)\n",
    "print(f\"train cross-validation score: {score:f}\")\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "y1_pred = clf.predict(X1)\n",
    "# \"overfitting\" on train dataset should about return 1.0 (max) as score\n",
    "print(f\"R² Score train: {r2_score(y_cls, y_pred)}, test: {r2_score(y1_cls, y1_pred)}\")\n",
    "print(f\"Accuracy Score train: {accuracy_score(y_cls, y_pred)}, test: {accuracy_score(y1_cls, y1_pred)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See sklearn: \"Nested versus non-nested cross-validation\"\n",
    "@ https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scratch area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "#p_grid = {\"C\": [1, 10, 100]}\n",
    "#svm = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "def run_trials_both(clf, p_grid, num_trials):\n",
    "    # Arrays to store scores\n",
    "    non_nested_scores = np.zeros(num_trials)\n",
    "    nested_scores = np.zeros(num_trials)\n",
    "\n",
    "    # Loop for each trial\n",
    "    for i in range(num_trials):\n",
    "\n",
    "        # Choose cross-validation techniques for the inner and outer loops,\n",
    "        # independently of the dataset.\n",
    "        # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "        inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "        clf.fit(X, y)\n",
    "        non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "        # Nested CV with parameter optimization\n",
    "        clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "        nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "        nested_scores[i] = nested_score.mean()\n",
    "\n",
    "    return non_nested_scores, nested_scores\n",
    "\n",
    "\n",
    "def plot_trials_both(non_nested_scores, nested_scores, num_trials):\n",
    "    # Plot scores on each trial for nested and non-nested CV\n",
    "    fig = plt.figure()\n",
    "    ax1, ax2 = fig.subplots(2, 1, sharex=True)\n",
    "    (non_nested_scores_line,) = ax1.plot(non_nested_scores, color=\"r\")\n",
    "    (nested_line,) = ax1.plot(nested_scores, color=\"b\")\n",
    "\n",
    "    ax1.set_title(\"Non-Nested and Nested Cross Validation\", x=0.5, y=1.1, fontsize=\"15\",)\n",
    "\n",
    "    ax1.set_ylabel(\"score\", fontsize=\"14\")\n",
    "    ax1.legend(\n",
    "        [non_nested_scores_line, nested_line],\n",
    "        [\"Non-Nested CV\", \"Nested CV\"],\n",
    "        bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
    "    )\n",
    "    \n",
    "    # Plot bar chart of the difference.\n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "    difference_plot = plt.bar(range(num_trials), score_difference)\n",
    "    ax2.set_xlabel(\"Individual Trial #\")\n",
    "    ax2.set_ylabel(\"score difference\", fontsize=\"14\")\n",
    "    ax2.legend(\n",
    "        [difference_plot],\n",
    "        [\"Non-Nested CV - Nested CV Score\"],\n",
    "        bbox_to_anchor=(0, 1, 0.8, 0),\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "non_nested_scores, nested_scores = run_trials_both(svm, p_grid, NUM_TRIALS)\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\".format(score_difference.mean(), score_difference.std()))\n",
    "\n",
    "fig = plot_trials_both(non_nested_scores, nested_scores, NUM_TRIALS)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
